{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVuz0hhFdyqB"
   },
   "source": [
    "# [Taller] Introducción NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqfuRZMnU25k"
   },
   "source": [
    "Procesamiento de Lenguaje Natural - 3011176"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw1jeTu9HIbj"
   },
   "source": [
    "**Objetivo**\n",
    "Realizar unos ejercicios para poner en practica la manipulacion de texto en python\n",
    "\n",
    "**Contenido**\n",
    "- Limpieza de texto\n",
    "- Normalización de texto\n",
    "- Pyspellchecker\n",
    "- Preprocesamiento\n",
    "- Librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjDd0bR6TOx_"
   },
   "source": [
    "##Consideraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4rpr0t7TQqz"
   },
   "source": [
    "Ejecute el cuaderno en orden\n",
    "NO modifique el primer bloque del ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T14mk8BDGIW0"
   },
   "source": [
    "## Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmeWhf9hAo9-"
   },
   "source": [
    "Use [Pyspellchecker](https://pyspellchecker.readthedocs.io/en/latest/) para corregir la ortografia del texto, imprima para cada palabra mal escrita 2 candidatos para remplazar dicha palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T22:00:10.869831Z",
     "iopub.status.busy": "2025-10-01T22:00:10.869831Z",
     "iopub.status.idle": "2025-10-01T22:00:15.831630Z",
     "shell.execute_reply": "2025-10-01T22:00:15.831020Z",
     "shell.execute_reply.started": "2025-10-01T22:00:10.869831Z"
    },
    "id": "Mu9UJ46_Gl48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Palabra mal escrita: 'pueblito', Candidatos: ['pueblo']\n",
      "Palabra mal escrita: 'pueblito', Candidatos: ['pueblo']\n",
      "Palabra mal escrita: 'cambiaria', Candidatos: ['cambiavía', 'cambiadiza']\n",
      "Palabra mal escrita: 'dai', Candidatos: ['cai', 'di']\n",
      "Palabra mal escrita: 'cambiaria', Candidatos: ['cambiavía', 'cambiadiza']\n",
      "Palabra mal escrita: 'dai', Candidatos: ['cai', 'di']\n",
      "Palabra mal escrita: 'estrelas', Candidatos: ['estrellar', 'estrella']\n",
      "Palabra mal escrita: 'soñaba', Candidatos: ['sorba', 'solana']\n",
      "Palabra mal escrita: 'estrelas', Candidatos: ['estrellar', 'estrella']\n",
      "Palabra mal escrita: 'soñaba', Candidatos: ['sorba', 'solana']\n",
      "Palabra mal escrita: 'arboles', Candidatos: ['artolas', 'arboleda']\n",
      "Palabra mal escrita: 'flores', Candidatos: ['floreo']\n",
      "Palabra mal escrita: 'tornaba', Candidatos: ['tornada']\n",
      "Palabra mal escrita: 'zaber', Candidatos: ['saber', 'caber']\n",
      "Palabra mal escrita: 'avanzaba', Candidatos: ['avanzada']\n",
      "Palabra mal escrita: 'arboles', Candidatos: ['artolas', 'arboleda']\n",
      "Palabra mal escrita: 'flores', Candidatos: ['floreo']\n",
      "Palabra mal escrita: 'tornaba', Candidatos: ['tornada']\n",
      "Palabra mal escrita: 'zaber', Candidatos: ['saber', 'caber']\n",
      "Palabra mal escrita: 'avanzaba', Candidatos: ['avanzada']\n",
      "Palabra mal escrita: 'intrigada', Candidatos: ['intrigar', 'entripada']\n",
      "Palabra mal escrita: 'vivya', Candidatos: ['viva']\n",
      "Palabra mal escrita: 'intrigada', Candidatos: ['intrigar', 'entripada']\n",
      "Palabra mal escrita: 'vivya', Candidatos: ['viva']\n",
      "Palabra mal escrita: 'encontro', Candidatos: ['encontrar', 'enconado']\n",
      "Palabra mal escrita: 'encontro', Candidatos: ['encontrar', 'enconado']\n",
      "Palabra mal escrita: 'aventurarses', Candidatos: []\n",
      "Palabra mal escrita: 'parecia', Candidatos: ['paresia', 'paremia']\n",
      "Palabra mal escrita: 'decidio', Candidatos: ['decidir', 'deicidio']\n",
      "Palabra mal escrita: 'misteriosos', Candidatos: ['misterioso']\n",
      "Palabra mal escrita: 'eran', Candidatos: ['cran', 'erar']\n",
      "Palabra mal escrita: 'altos', Candidatos: ['alto', 'altor']\n",
      "Palabra mal escrita: 'ojos', Candidatos: ['ojoso', 'ojo']\n",
      "Palabra mal escrita: 'aventurarses', Candidatos: []\n",
      "Palabra mal escrita: 'parecia', Candidatos: ['paresia', 'paremia']\n",
      "Palabra mal escrita: 'decidio', Candidatos: ['decidir', 'deicidio']\n",
      "Palabra mal escrita: 'misteriosos', Candidatos: ['misterioso']\n",
      "Palabra mal escrita: 'eran', Candidatos: ['cran', 'erar']\n",
      "Palabra mal escrita: 'altos', Candidatos: ['alto', 'altor']\n",
      "Palabra mal escrita: 'ojos', Candidatos: ['ojoso', 'ojo']\n",
      "Palabra mal escrita: 'despertaba', Candidatos: ['despernada', 'despertar']\n",
      "Palabra mal escrita: 'bosques', Candidatos: ['bosque']\n",
      "Palabra mal escrita: 'lamada', Candidatos: ['lamida', 'famada']\n",
      "Palabra mal escrita: 'recogia', Candidatos: ['recogida']\n",
      "Palabra mal escrita: 'iba', Candidatos: ['riba', 'iza']\n",
      "Palabra mal escrita: 'despertaba', Candidatos: ['despernada', 'despertar']\n",
      "Palabra mal escrita: 'bosques', Candidatos: ['bosque']\n",
      "Palabra mal escrita: 'lamada', Candidatos: ['lamida', 'famada']\n",
      "Palabra mal escrita: 'recogia', Candidatos: ['recogida']\n",
      "Palabra mal escrita: 'iba', Candidatos: ['riba', 'iza']\n",
      "Palabra mal escrita: 'brillaban', Candidatos: []\n",
      "Palabra mal escrita: 'nina', Candidatos: ['pina', 'tina']\n",
      "Palabra mal escrita: 'sombras', Candidatos: ['sombra', 'sombrar']\n",
      "Palabra mal escrita: 'lejado', Candidatos: ['dejado', 'lejano']\n",
      "Palabra mal escrita: 'brillaban', Candidatos: []\n",
      "Palabra mal escrita: 'nina', Candidatos: ['pina', 'tina']\n",
      "Palabra mal escrita: 'sombras', Candidatos: ['sombra', 'sombrar']\n",
      "Palabra mal escrita: 'lejado', Candidatos: ['dejado', 'lejano']\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspellchecker # '%' instala especificamente en el entrono del kernel actual\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "historia = \"\"\"Un dai, en un pueblito lejado, vivya una nina lamada Lila que soñaba con aventurarses.\n",
    "Cada mañana, ella se despertaba temprano para explorar el bosques cercano, donde los arboles eran altos y misteriosos.\n",
    "Un día, mientras recogia flores, se encontro con un gato negro que parecia tener ojos que brillaban como estrelas.\n",
    "Lila, intrigada, decidio seguir al gato, sin zaber que lo que iba a descubrir cambiaria su vida para siempre.\n",
    "A medida que avanzaba, el sendero se tornaba mas oscuro y lleno de sombras, pero su curiosidad era mas fuerte que su miedo.\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "spell = SpellChecker(language='es')\n",
    "\n",
    "# Dividir el texto en palabras y convertir a minúsculas\n",
    "palabras = re.findall(r'[a-záéíóúñü]+', historia.lower())\n",
    "\n",
    "palabras_mal_escritas = spell.unknown(palabras)\n",
    "\n",
    "for palabra in palabras_mal_escritas:\n",
    "    # Obtener los 2 candidatos más probables\n",
    "    candidatos_palabra = spell.candidates(palabra)\n",
    "    if candidatos_palabra: # Verificar si hay candidatos\n",
    "      print(f\"Palabra mal escrita: '{palabra}', Candidatos: {list(candidatos_palabra)[:2]}\")\n",
    "    else:\n",
    "      print(f\"Palabra mal escrita: '{palabra}', Candidatos: []\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PLX4lISqkKa"
   },
   "source": [
    "##Preprocesamiento usando python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d6pvAySJ1B9"
   },
   "source": [
    "Python nos ofrece metodos propios del lenguaje que nos ayudan con tareas basicas de preprocesamiento de texto, por ejemplo el metodo .replace() que nos ayuda a remplazar caracteres en un objeto string o el metodo .split() que nos ayuda a tokenisar o separar las palabras de un texto ya sea por espacios en blanco o otro caracter estipulado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BryxpZPDqqqk"
   },
   "source": [
    "Actividad: Tokenice la variable **frase** usando el metodo .split(), haga una limpieza basica de caracteres y por ultimo imprima el resultado\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-25T14:50:28.039451Z",
     "iopub.status.idle": "2025-09-25T14:50:28.039451Z",
     "shell.execute_reply": "2025-09-25T14:50:28.039451Z",
     "shell.execute_reply.started": "2025-09-25T14:50:28.039451Z"
    },
    "id": "GZVzHCyUrlEa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'un', 'pueblo', 'rodeado', 'de', 'montañas', 'vivia', 'una', 'anciana', 'llamada', 'Clara', 'Cada', 'dia', 'salia', 'al', 'jardin', 'a', 'regar', 'sus', 'flores']\n"
     ]
    }
   ],
   "source": [
    "frase = \"en un pueblo rodeado de montañas, vivia una anciana llamada Clara. Cada dia, salia al jardin a regar sus flores\"\n",
    "\n",
    "# Tokenizar la frase usando .split() \n",
    "tokens = frase.split()\n",
    "\n",
    "# Realizar limpieza básica de caracteres (eliminar puntuación)\n",
    "tokens_limpios = []\n",
    "for token in tokens:\n",
    "    # Eliminar puntuación usando isalpha()\n",
    "    token_limpio = ''.join(char for char in token if char.isalpha())\n",
    "    if token_limpio: # Añadir solo si no está vacío después de la limpieza\n",
    "        tokens_limpios.append(token_limpio)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(tokens_limpios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFju7fYArpcE"
   },
   "source": [
    "Las \"Stop words\", son palabras comunes que generalmente se eliminan de los textos antes de realizar análisis o procesamiento. Estas palabras suelen incluir artículos, preposiciones, pronombres y otros términos que no aportan mucho significado al contexto, como \"el\", \"y\", \"a\", \"en\", \"de\", etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MEvRQn7WEFA"
   },
   "source": [
    "Actividad: Cree un diccionario de stop words y elimine dichas palabras del array anteriormente creado e imprima el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a-dNZkzPro41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pueblo', 'rodeado', 'montañas', 'vivia', 'anciana', 'llamada', 'Clara', 'dia', 'salia', 'jardin', 'regar', 'flores']\n"
     ]
    }
   ],
   "source": [
    "# Crear un conjunto (diccionario) de palabras vacías (stop words)\n",
    "# Este es un ejemplo básico, para listas más completas, considere las stop words de NLTK más adelante\n",
    "stop_words = set([\"en\", \"un\", \"de\", \"una\", \"cada\", \"al\", \"a\", \"sus\"])\n",
    "\n",
    "# Eliminar palabras vacías de la lista de tokens limpios\n",
    "tokens_filtrados = [palabra for palabra in tokens_limpios if palabra.lower() not in stop_words]\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(tokens_filtrados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr1R9iMoI3gc"
   },
   "source": [
    "Actividad: Recopilacion de tareas en el preprocesamiento de texto\n",
    "- Cargue el texto romeo_juliet.txt adjunto al taller.\n",
    "- Dividalo en tokens.\n",
    "- Conviertalo a minúsculas.\n",
    "- Elimine la puntuación de cada token, puede usar el metodo .isalpha() de python\n",
    "- Filtre los tokens restantes que no sean alfabéticos.\n",
    "- Filtre los tokens que son palabras vacías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T22:02:15.602765Z",
     "iopub.status.busy": "2025-10-01T22:02:15.602765Z",
     "iopub.status.idle": "2025-10-01T22:02:15.636904Z",
     "shell.execute_reply": "2025-10-01T22:02:15.636904Z",
     "shell.execute_reply.started": "2025-10-01T22:02:15.602765Z"
    },
    "id": "98a2fQppKwTy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens preprocesados:\n",
      "['project', 'gutenberg', 'ebook', 'romeo', 'juliet', 'ebook', 'use', 'anyone', 'anywhere', 'united', 'states', 'most', 'other', 'parts', 'world', 'at', 'no', 'cost', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'give', 'away', 'or', 're', 'use', 'under', 'terms', 'project', 'gutenberg', 'license', 'included', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'org', 'if', 'you', 'are', 'not', 'located', 'united', 'states', 'you', 'will', 'have', 'check', 'laws', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'ebook', 'title', 'romeo', 'juliet', 'author', 'william', 'shakespeare', 'release', 'date', 'november', 'ebook', 'most', 'recently', 'updated', 'june', 'language', 'english', 'credits', 'pg', 'shakespeare', 'team', 'team', 'about', 'twenty', 'project', 'gutenberg', 'volunteers', 'start', 'project', 'gutenberg', 'ebook', 'romeo', 'juliet', 'tragedy', 'romeo', 'juliet', 'by', 'william']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "# Cargar el texto romeo_juliet.txt\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__' if '__file__' in globals() else '.'))\n",
    "repo_root = os.path.dirname(notebook_dir)\n",
    "archivo_path = os.path.join(repo_root, 'data', 'romeo_juliet.txt')\n",
    "\n",
    "# Dividir el texto en tokens (palabras) y convertir a minúsculas\n",
    "# Usaremos una expresión regular para incluir palabras con tildes y ñ si es necesario, o solo alfabéticas simples\n",
    "tokens = re.findall(r'[a-zA-ZáéíóúüñÁÉÍÓÚÜÑ]+', texto_romeo_juliet.lower())\n",
    "\n",
    "# Eliminar la puntuación y filtrar tokens no alfabéticos\n",
    "tokens_alfabeticos = [token for token in tokens if token.isalpha()]\n",
    "\n",
    "# Crear un conjunto de stop words manualmente en inglés\n",
    "stop_words = set([\"the\", \"a\", \"an\", \"is\", \"it\", \"in\", \"of\", \"on\", \"and\", \"to\", \"for\", \"with\", \"that\", \"this\", \"be\"])\n",
    "\n",
    "# Filtrar las stop words de los tokens alfabéticos\n",
    "tokens_filtrados = [token for token in tokens_alfabeticos if token not in stop_words]\n",
    "\n",
    "# Imprimir el resultado del preprocesamiento (los tokens finales)\n",
    "print(\"Tokens preprocesados:\")\n",
    "print(tokens_filtrados[:100]) # Imprimir solo los primeros 100 tokens para brevedad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcEe6ZRHBuKI"
   },
   "source": [
    "FACULTAD DE MINAS<br>\n",
    "Sede Medellín"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf9FvxRf46pB"
   },
   "source": [
    "SINTELWEB<br>\n",
    "Grupo de Investigación<br>\n",
    "Sistemas Inteligentes"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "chatbotestructuras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
